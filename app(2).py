# -*- coding: utf-8 -*-
"""Streamlit ECG Predictor with Preprocessing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VQgoiRWuFk9gBy03kqCe3C1bPmJRnh2d
"""

import streamlit as st
import tensorflow as tf
import numpy as np
import pandas as pd
import wfdb
from scipy.signal import resample
import io
import time
from keras.models import load_model

# --- Configuration and Constants ---
# Model path and expected input shape
MODEL_PATH = 'model_B_noisy.keras' # UPDATED MODEL FILE NAME
INPUT_LENGTH = 187

# Frequencies for MIT-BIH (Original FS) and common target FS for models
ORIGINAL_FS = 360 # Assuming MIT-BIH original frequency
TARGET_FS = 125 # Common target frequency for many ECG models

# Mapping of model output index to MIT-BIH arrhythmia classes
# Please verify these labels against your model's output structure.
CLASS_LABELS = {
    0: "N - Normal Beat (Non-ectopic)",
    1: "S - Supraventricular Ectopic Beat (Aberrant)",
    2: "V - Ventricular Ectopic Beat",
    3: "F - Fusion Beat (Normal and Ectopic)",
    4: "Q - Unknown Beat"
}

# --- Caching and Utility Functions ---

@st.cache_resource
def load_keras_model(path):
    """Loads the Keras model with a resource cache."""
    try:
        # Suppress internal Keras warnings
        tf.get_logger().setLevel('ERROR')
        model = load_model(path)
        st.sidebar.success("Model loaded successfully!")
        return model
    except Exception as e:
        st.error(f"Error loading model from {path}: {e}")
        st.info(f"Please make sure '{MODEL_PATH}' is in the same directory as this script.")
        return None

def normalize_segment(segment):
    """Min-Max Normalization of the 187-point segment."""
    segment = segment.astype(np.float32)
    min_val = np.min(segment)
    max_val = np.max(segment)

    # Check to prevent division by zero or near-zero range
    if (max_val - min_val) > 1e-6:
        normalized = (segment - min_val) / (max_val - min_val)
    else:
        # If signal is flat, normalization is meaningless
        normalized = segment * 0

    return normalized

def preprocess_and_predict(full_signal_1d, r_peak_index_360hz, model):
    """
    Core preprocessing pipeline: Resample, Segment, Normalize, Reshape, Predict.

    Args:
        full_signal_1d (np.ndarray): The raw, full ECG signal (e.g., from an uploaded CSV).
        r_peak_index_360hz (int): The index of the R-peak in the *original* 360 Hz signal.
        model (tf.keras.Model): The loaded Keras model.

    Returns:
        tuple: (prediction_probabilities, normalized_segment) or (None, None) on failure.
    """

    st.markdown("#### Preprocessing Pipeline")

    # 1. Resampling
    st.info(f"1. Resampling signal from {ORIGINAL_FS} Hz to {TARGET_FS} Hz...")

    original_len = len(full_signal_1d)
    new_len = int(original_len * TARGET_FS / ORIGINAL_FS)

    # Resample the entire signal using scipy's resample
    resampled_signal = resample(full_signal_1d, new_len)

    # Calculate the equivalent R-peak index in the resampled signal
    r_peak_index_125hz = int(r_peak_index_360hz * TARGET_FS / ORIGINAL_FS)
    st.caption(f"Original R-peak index: {r_peak_index_360hz} (360Hz) -> New R-peak index: {r_peak_index_125hz} (125Hz)")

    # 2. Segmentation (187 points)
    # The segment length is 187. We take 93 points before and 93 points after the R-peak (187 = 93 + 1 + 93).
    half_len = (INPUT_LENGTH - 1) // 2
    start_index = r_peak_index_125hz - half_len
    end_index = r_peak_index_125hz + half_len + 1 # +1 is needed because slicing is exclusive

    # Check bounds (ensure segment fits within the resampled signal)
    if start_index < 0 or end_index > len(resampled_signal):
        st.error(f"Cannot extract a full {INPUT_LENGTH}-point segment at the calculated R-peak index. Signal bounds exceeded.")
        return None, None

    segment = resampled_signal[start_index:end_index]
    st.success(f"2. Segment extracted: Indices {start_index} to {end_index-1} (Length: {len(segment)})")

    # 3. Normalization and Reshape
    normalized_segment = normalize_segment(segment)
    # Reshape for Keras: (Batch Size, Timesteps, Channels) -> (1, 187, 1)
    model_input = normalized_segment.reshape(1, INPUT_LENGTH, 1)
    st.success("3. Segment Normalized and Reshaped to (1, 187, 1)")

    # 4. Prediction
    with st.spinner('Running inference with model_bnoisy...'):
        # Ensure the model is available before predicting
        if model is None:
            return None, None

        prediction_probabilities = model.predict(model_input)[0]
        time.sleep(0.5)

    return prediction_probabilities, normalized_segment

def display_results(prediction_probabilities, segment):
    """Displays the final prediction and charts."""
    predicted_class_index = np.argmax(prediction_probabilities)
    predicted_class_label = CLASS_LABELS.get(predicted_class_index, f"Class {predicted_class_index}")
    predicted_score = prediction_probabilities[predicted_class_index]

    st.markdown("---")
    st.subheader("âœ… Prediction Result")

    # Display the final classification
    st.metric(
        label="Predicted Arrhythmia Type",
        value=f"{predicted_class_label}",
        delta=f"{predicted_score*100:.2f}% Confidence"
    )

    # Probability chart
    st.subheader("Probability Distribution")
    prob_data = {
        "Arrhythmia Class": [CLASS_LABELS.get(i, f"Class {i}") for i in range(len(prediction_probabilities))],
        "Probability": prediction_probabilities
    }
    prob_df = pd.DataFrame(prob_data)

    st.bar_chart(prob_df, x="Arrhythmia Class", y="Probability", color="#3498db")

    # Signal plot
    st.subheader(f"Extracted and Normalized Beat ({INPUT_LENGTH} points)")
    # Convert segment to DataFrame for Streamlit plotting
    segment_df = pd.DataFrame(segment, columns=['Amplitude'])
    st.line_chart(segment_df, use_container_width=True)


# --- Streamlit Application Layout ---

def main():
    st.set_page_config(
        page_title="model_bnoisy ECG Predictor",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("CardiAI: Arrhythmia Prediction with `model_B_noisy.keras`")
    st.markdown("A demonstration of ECG beat classification including mandatory signal preprocessing (resampling).")

    # Load the model (done in sidebar for visibility)
    model = load_keras_model(MODEL_PATH)

    # Sidebar for Model Info and instructions
    with st.sidebar:
        st.header("Model and Signal Specs")
        st.markdown(f"**Model File:** `{MODEL_PATH}`")
        st.markdown(f"**Target Input Length:** **{INPUT_LENGTH} points**")
        st.markdown(f"**Signal Resampling:** **{ORIGINAL_FS} Hz â†’ {TARGET_FS} Hz**")

        st.markdown("---")
        st.header("Libraries Required")
        st.markdown("""
        Ensure you have installed:
        - `streamlit`
        - `tensorflow`
        - `pandas`
        - `numpy`
        - `wfdb` (for PhysioNet data)
        - `scipy` (for resampling)
        """)
        st.markdown("---")
        st.warning(f"The model file `{MODEL_PATH}` must be in the same folder.")


    tab1, tab2 = st.tabs(["ðŸ“Š PhysioNet Sample Test", "ðŸ“‚ Upload Your Own CSV"])

    # --- Tab 1: PhysioNet Sample Test ---
    with tab1:
        st.header("Test with PhysioNet Sample Data (MIT-BIH)")
        st.markdown("""
            Fetches **Record 100** from the MIT-BIH database to demonstrate the complete preprocessing and prediction pipeline on a known signal.
        """)

        # We will use a known R-peak index from Record 100 for a sample beat (Index 2000 is a safe N-beat)
        record_name = '100'
        # This index is based on the original 360 Hz signal, which is critical for the pipeline.
        sample_r_peak_index_360hz = st.slider(
            f"Select R-Peak Index in Record {record_name} (360 Hz)",
            min_value=1000, max_value=5000, value=2000, step=10
        )

        if st.button(f"Run Prediction on MIT-BIH Record {record_name}"):
            if model is None:
                st.error("Model is not loaded. Cannot run prediction.")
                return

            try:
                # 1. Fetch data
                with st.spinner(f"Fetching record {record_name} from PhysioNet..."):
                    # Only fetch channel 0 (MLII lead)
                    record = wfdb.rdrecord(record_name, pn_dir='mitdb/1.0.0/', channels=[0])
                    full_signal_360hz = record.p_signal[:, 0]

                st.success(f"Fetched {len(full_signal_360hz)} data points from Record {record_name}.")

                # 2. Preprocess and Predict
                probs, segment = preprocess_and_predict(
                    full_signal_360hz,
                    sample_r_peak_index_360hz,
                    model
                )

                if probs is not None:
                    display_results(probs, segment)

            except Exception as e:
                st.error("Error fetching or processing PhysioNet data.")
                st.exception(e)
                st.info("Check your internet connection and ensure `wfdb` and `scipy` are installed.")

    # --- Tab 2: CSV Upload ---
    with tab2:
        st.header("Upload Your ECG Signal")
        st.markdown("""
            Upload a single-column CSV file containing a raw ECG signal (assumed to be **360 Hz**).
            You must provide the R-peak index (based on the **original 360 Hz** data) to center the beat.
        """)

        uploaded_file = st.file_uploader(
            "Choose a raw ECG signal CSV file",
            type="csv"
        )

        r_peak_index_input = st.number_input(
            "Enter R-Peak Index (Index in the original 360 Hz signal)",
            min_value=0,
            value=500,
            step=1
        )

        if uploaded_file is not None:
            # Read the file into a DataFrame
            try:
                # Use squeeze to ensure it's a Series (1D data)
                df = pd.read_csv(uploaded_file, header=None).squeeze()

                st.subheader("1. Uploaded Signal Preview (360 Hz)")
                st.line_chart(df, use_container_width=True)
                st.text(f"Loaded {len(df)} data points at 360 Hz.")

                if st.button("Classify Uploaded Signal", key="upload_classify_btn"):
                    if model is None:
                        st.error("Model is not loaded. Cannot run prediction.")
                        return

                    full_signal_360hz = df.values.flatten()

                    if len(full_signal_360hz) == 0:
                        st.warning("The uploaded file is empty.")
                        return

                    # Preprocess and Predict
                    probs, segment = preprocess_and_predict(
                        full_signal_360hz,
                        r_peak_index_input,
                        model
                    )

                    if probs is not None:
                        display_results(probs, segment)

            except Exception as e:
                st.error(f"An error occurred during file processing or prediction.")
                st.exception(e)
                st.info("Ensure the CSV file is a single column of numerical data.")

if __name__ == '__main__':
    main()
